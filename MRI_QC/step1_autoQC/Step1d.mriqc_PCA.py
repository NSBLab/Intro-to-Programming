print('Initialising arguments...')
import numpy as np
import pandas as pd
from scipy import stats
from sklearn import preprocessing
from sklearn import decomposition
import matplotlib.pyplot as plt
import argparse

parser = argparse.ArgumentParser(description=
                                 'Run a Principal Component Analysis on selected group-level outputs from MRIQC')
parser.add_argument('InputFile', metavar='</path/to/mriqc/group_T1w.tsv>', type=str,
                    help='The path to your MRIQC group_T1w.tsv file')
parser.add_argument('--SDthreshold', type=int, default=3.5,
                    help='Specify how many SDs each subject must be above/below the mean of a given component '
                         'to be flagged as an outlier. Higher threshold = less strict and fewer outliers flagged, '
                         'lower threshold = more strict and more outliers flagged. Default = 3.5')
parser.add_argument('--PCthreshold', type=int, default=80,
                    help='PCA will keep the first n components that explain PCthreshold%% of the variance in the '
                         'orignal data. Higher threshold = greater number of PCs kept and more outliers flagged, '
                         'lower threshold = fewer PCs kept and less outliers flagged. Default = 80. If '
                         '--percent=False, this argument will instead determine the number PCs kept regardless of '
                         'the cumulative variance explained (e.g., the first 5 components)')
parser.add_argument('--percent', type=str, default='True', choices=['True', 'False', 'T', 'F', 'true', 'false'],
                    help='Select PCs to keep based on the first n that explain a minimum percentage of variance '
                         'in the original data. If False, you can manually specify the exact number of PCs to keep '
                         'instead (not recommended unless later PCs explain a very small %% of variance). '
                         'Default = True')
parser.add_argument('OutputDirectory', metavar='</path/to/mriqc/output>', type=str,
                    help='The path to your output directory for the PCA results and flagged subject IDs')

args = parser.parse_args()
print(args)
print('')
print('----- START -----')
print('')

# Load in your data and the output directory where you'll save the PCA outputs
# This should be the group_T1w.tsv file generated by MRIQC
data = pd.read_csv(args.InputFile, sep='\t', index_col='bids_name')
outdir = args.OutputDirectory

# Specify thresholds (how many SDs above/below the mean of a given component to be flagged as an outlier)
# Higher threshold = less strict and fewer outliers flagged, lower threshold = more strict and more outliers flagged
# Recommended 3.5
SDthresh = args.SDthreshold

# Do you want to keep the first n components that explain a certain amount of variance
# (i.e. 80% of variance in original data; True) or keep a specific number
# of components (i.e. first 5 components only; False)
# Recommended True
percentvar = args.percent

# Specify percent of variance explained (i.e. 80) or number of components to keep (i.e. 5)
# Greater number of components kept = more strict, fewer components = less strict
# Recommended 80
PCthresh = args.PCthreshold

# Mean centre the data and remove summary stats
# This is done prior to running the PCA to ensure the decomposition isn't biased
# by specific factors with smaller/larger ranges of values

data = data.drop(columns=['fwhm_x', 'fwhm_y', 'fwhm_z', 'inu_range', 'size_x', 'size_y', 'size_z', 'spacing_x', 'spacing_y', 'spacing_z', 'summary_bg_k', 'summary_bg_mad', 'summary_bg_mean', 'summary_bg_median', 'summary_bg_n', 'summary_bg_p05', 'summary_bg_p95', 'summary_bg_stdv', 'summary_csf_k', 'summary_csf_mad', 'summary_csf_mean', 'summary_csf_median', 'summary_csf_n', 'summary_csf_p05', 'summary_csf_p95', 'summary_csf_stdv', 'summary_gm_k', 'summary_gm_mad', 'summary_gm_mean', 'summary_gm_median', 'summary_gm_n', 'summary_gm_p05', 'summary_gm_p95', 'summary_gm_stdv', 'summary_wm_k', 'summary_wm_mad', 'summary_wm_mean', 'summary_wm_median', 'summary_wm_n', 'summary_wm_p05', 'summary_wm_p95', 'summary_wm_stdv'])
scaler = preprocessing.StandardScaler().fit(data)
data_mc = scaler.transform(data)

# Run PCA
# This will only keep the first n components specified by the 'PCthreshold' variable earlier
if percentvar == 'True' or percentvar == 'T' or percentvar == 'true':
    PCthresh = PCthresh/100
pca = decomposition.PCA(n_components=PCthresh, svd_solver='full')
pca_out = pca.fit_transform(data_mc)

print(f'The first {pca.n_components_} components explained {np.round(np.sum(pca.explained_variance_ratio_)*100, 3)}% '
      f'of the variance in group-level IQMs from MRIQC')

# z-scores for outliers
# This normalises the results of the PCA so we can find the subjects with the most deviant scores
# (i.e. the subjects with the most extreme QC scores)
# You'll typically get a somewhat skewed spread with poor quality scans having higher absolute z-scores
# In theory, the highest quality scans could also be flagged as outliers in the other direction,
# so you'll want to still manually inspect the outputs with respect to the z-score for each PC
# That said, in practice, the best quality scans still score closer to the mean than most outliers,
# so this is only a major issue if you set the threshold too low
# Still check your results though PLEASE!! This is SEMIautoQC

pca_out = stats.zscore(pca_out)

# Visualise eigens and variance explained
# This is a scree plot that helps illustrate which PCs explain the most variance in the original MRIQC data
# If you find that you've kept the first 80% but some later PCs explain very little variance,
# you might want to adjust the number of components you keep for example
# Usually this is fine, but it's important to check and inspect

# pca.explained_variance_ratio_ contains the eigenvalues of the covariance matrix for each component
# Summing this provides the cumulative variance for all components up until the nth component
# e.g. the amount of variance of your original data that can be explained by using the first n components alone

x = range(1, pca.n_components_+1, 1)
y = np.cumsum(pca.explained_variance_ratio_)
plt.plot(x, y)
plt.xlabel('Number of components')
plt.ylabel('Cumulative variance explained (%)')
plt.ylim([0, 1])
plt.xlim([1, pca.n_components_+0.5])
plt.xticks(x)
plt.yticks([0, 0.2, 0.4, 0.6, 0.8, 1], [0, 20, 40, 60, 80, 100])
plt.yticks([0.1, 0.3, 0.5, 0.7, 0.9], [], minor=True)
plt.grid(True, which='major', color='grey', axis='y')
plt.grid(True, which='minor', color='lightgrey', axis='y')
plt.savefig(f'{outdir}/PCA_cumvar.png')
plt.close()

plt.plot(x, pca.explained_variance_ratio_)
plt.xlabel('Component')
plt.ylabel('Variance explained (%)')
plt.ylim([0, 1])
plt.xlim([1, pca.n_components_+0.5])
plt.xticks(x)
plt.yticks([0, 0.2, 0.4, 0.6, 0.8, 1], [0, 20, 40, 60, 80, 100])
plt.yticks([0.1, 0.3, 0.5, 0.7, 0.9], [], minor=True)
plt.grid(True, which='major', color='grey', axis='y')
plt.grid(True, which='minor', color='lightgrey', axis='y')
plt.savefig(f'{outdir}/PCA_screeplot.png')
plt.close()

# Add IDs and labels to PCA
# This just reorganises the PCA outputs into a pandas DataFrame with a clear index and
# column labels for user reference

rows, cols = pca_out.shape
PC_labels = np.arange(cols)
PC_labels = [x+1 for x in PC_labels]
PC_labels = ['PC' + str(x) for x in PC_labels]
pca_out = pd.DataFrame(data=pca_out, index=data.index, columns=PC_labels)

# Flag outliers with z-score above/below threshold
# This uses the SDthreshold set earlier to find values above positive SDthreshold
# and below negative SDthreshold at each PC
# These are then saved as a list for manual inspections later
# Rather than needing to inspect an entire dataset, you can just inspect this shortlist
outliers = pca_out[(pca_out[PC_labels] >= SDthresh) | (pca_out[PC_labels] <= SDthresh*-1)].dropna(how='all')
clean_subs = pca_out[(pca_out[PC_labels] < SDthresh) & (pca_out[PC_labels] > SDthresh*-1)].dropna(how='any')

print(f'{len(outliers)} subjects were identified and flagged for visual inspection using a threshold '
      f'of {SDthresh} standard deviations across {pca.n_components_} principal components broadly '
      f'corresponding to image quality')

# Save results
pca_out.to_csv('{}/MRIQC_PCA.csv'.format(outdir), encoding='utf-8-sig')
pd.Series(outliers.index).to_csv('{}/outlier_list.txt'.format(outdir), header=False, index=False, encoding='utf-8-sig')
pd.Series(clean_subs.index).to_csv('{}/clean_subs.txt'.format(outdir), header=False, index=False, encoding='utf-8-sig')

print('')
print(f'Saved results to {outdir}')
print('')
print('-----  END  -----')
print('')
print('Make sure to manually inspect any subjects flagged by this method before removing them from analyses!!')
print('This can be done in FreeSurfer or FSLeyes depending on your preferences')
print('')
